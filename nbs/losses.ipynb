{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy Evaluation\n",
    "\n",
    "> NumPy loss functions aimed to be used during the models' evaluation. The most important train signal is the forecast error, which is the difference between the observed value $y_{\\tau}$ and the prediction $\\hat{y}_{\\tau}$, at time $y_{\\tau}$:$$e_{\\tau} = y_{\\tau}-\\hat{y}_{\\tau} \\qquad \\qquad \\tau \\in \\{t+1,\\dots,t+H \\}$$ The train loss summarizes the forecast errors in different evaluation metrics.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Optional, Union\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.display import Image\n",
    "WIDTH = 600\n",
    "HEIGHT = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _divide_no_nan(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Auxiliary funtion to handle divide by 0\n",
    "    \"\"\"\n",
    "    div = a / b\n",
    "    div[div != div] = 0.0\n",
    "    div[div == float('inf')] = 0.0\n",
    "    return div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _metric_protections(y: np.ndarray, y_hat: np.ndarray, weights: np.ndarray) -> None:\n",
    "    assert (weights is None) or (np.sum(weights) > 0), 'Sum of weights cannot be 0'\n",
    "    assert (weights is None) or (weights.shape == y.shape),\\\n",
    "        f'Wrong weight dimension weights.shape {weights.shape}, y.shape {y.shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkOrange\">1. Scale-dependent Errors </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mae(y: np.ndarray, y_hat: np.ndarray,\n",
    "        weights: Optional[np.ndarray] = None,\n",
    "        axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculates Mean Absolute Error (MAE) between\n",
    "    y and y_hat. MAE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the\n",
    "    deviation of the prediction and the true\n",
    "    value at a given time and averages these devations\n",
    "    over the length of the series.\n",
    "    \n",
    "    $$ \\mathrm{MAE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \n",
    "        \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} \n",
    "        |y_{\\\\tau} - \\hat{y}_{\\\\tau}| $$\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat: numpy array\n",
    "            Predicted values.\n",
    "        weights: numpy array, optional. \n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional. \n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the elements of \n",
    "            the input array. If axis is negative it counts from last to first.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mae: numpy array or double.\n",
    "            Return the MAE along the specified axis.\n",
    "    \"\"\"\n",
    "    _metric_protections(y, y_hat, weights)\n",
    "    \n",
    "    delta_y = np.abs(y - y_hat)\n",
    "    if weights is not None:\n",
    "        mae = np.average(delta_y[~np.isnan(delta_y)], \n",
    "                         weights=weights[~np.isnan(delta_y)],\n",
    "                         axis=axis)\n",
    "    else:\n",
    "        mae = np.nanmean(delta_y, axis=axis)\n",
    "        \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "mae_loss_image = Image(filename='loss_imgs/mae_loss.png', width=WIDTH, height=HEIGHT)\n",
    "mae_loss_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mse(y: np.ndarray, y_hat: np.ndarray, \n",
    "        weights: Optional[np.ndarray] = None,\n",
    "        axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculates Mean Squared Error (MSE) between\n",
    "    y and y_hat. MSE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the \n",
    "    squared deviation of the prediction and the true\n",
    "    value at a given time, and averages these devations\n",
    "    over the length of the series.\n",
    "    \n",
    "    $$ \\mathrm{MSE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \n",
    "        \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} (y_{\\\\tau} - \\hat{y}_{\\\\tau})^{2} $$\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array.\n",
    "            Actual test values.\n",
    "        y_hat: numpy array.\n",
    "            Predicted values.\n",
    "        weights: numpy array, optional.\n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional.\n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the \n",
    "            elements of the input array. If axis is negative it counts \n",
    "            from the last to the first axis.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mse: numpy array or double.\n",
    "            Return the MSE along the specified axis.\n",
    "    \"\"\"\n",
    "    _metric_protections(y, y_hat, weights)\n",
    "\n",
    "    delta_y = np.square(y - y_hat)\n",
    "    if weights is not None:\n",
    "        mse = np.average(delta_y[~np.isnan(delta_y)], \n",
    "                         weights=weights[~np.isnan(delta_y)], \n",
    "                         axis=axis)\n",
    "    else:\n",
    "        mse = np.nanmean(delta_y, axis=axis)\n",
    "        \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "mse_image = Image(filename='loss_imgs/mse_loss.png', width=WIDTH, height=HEIGHT)\n",
    "mse_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rmse(y: np.ndarray, y_hat: np.ndarray,\n",
    "         weights: Optional[np.ndarray] = None,\n",
    "         axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculates Root Mean Squared Error (RMSE) between\n",
    "    y and y_hat. RMSE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the squared deviation\n",
    "    of the prediction and the observed value at a given time and\n",
    "    averages these devations over the length of the series.\n",
    "    Finally the RMSE will be in the same scale\n",
    "    as the original time series so its comparison with other\n",
    "    series is possible only if they share a common scale. \n",
    "    RMSE has a direct connection to the L2 norm.\n",
    "    \n",
    "    $$ \\mathrm{RMSE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \n",
    "        \\\\sqrt{\\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} (y_{\\\\tau} - \\hat{y}_{\\\\tau})^{2}} $$\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat: numpy array. \n",
    "            Predicted values.    \n",
    "        weights: numpy array, optional. \n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional. \n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the elements of \n",
    "            the input array. If axis is negative it counts from the last to first.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        rmse: numpy array or double.\n",
    "            Return the RMSE along the specified axis.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt(mse(y, y_hat, weights, axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "rmse_loss_image = Image(filename='loss_imgs/rmse_loss.png', width=WIDTH, height=HEIGHT)\n",
    "rmse_loss_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkOrange\">2. Percentage Errors </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mape(y: np.ndarray, y_hat: np.ndarray, \n",
    "         weights: Optional[np.ndarray] = None,\n",
    "         axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculates Mean Absolute Percentage Error (MAPE) between\n",
    "    y and y_hat. MAPE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the percentual deviation\n",
    "    of the prediction and the observed value at a given time and\n",
    "    averages these devations over the length of the series.\n",
    "    The closer to zero an observed value is, the higher penalty MAPE loss\n",
    "    assigns to the corresponding error.\n",
    "    \n",
    "    $$ \\mathrm{MAPE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \n",
    "        \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1}\n",
    "        \\\\frac{|y_{\\\\tau}-\\hat{y}_{\\\\tau}|}{|y_{\\\\tau}|} $$\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat: numpy array. \n",
    "            Predicted values.    \n",
    "        weights: numpy array, optional. \n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional. \n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the elements of \n",
    "            the input array. If axis is negative it counts from the last to first.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mape: numpy array or double.\n",
    "            Return the MAPE along the specified axis.\n",
    "    \"\"\"\n",
    "    _metric_protections(y, y_hat, weights)\n",
    "        \n",
    "    delta_y = np.abs(y - y_hat)\n",
    "    scale = np.abs(y)\n",
    "    mape = _divide_no_nan(delta_y, scale)\n",
    "    mape = np.average(mape, weights=weights, axis=axis)\n",
    "    mape = 100 * mape\n",
    "    \n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "mape_image = Image(filename='loss_imgs/mape_loss.png', width=WIDTH, height=HEIGHT)\n",
    "mape_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def smape(y: np.ndarray, y_hat: np.ndarray,\n",
    "          weights: Optional[np.ndarray] = None,\n",
    "          axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculates Symmetric Mean Absolute Percentage Error (SMAPE) between\n",
    "    y and y_hat. SMAPE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the relative deviation\n",
    "    of the prediction and the observed value scaled by the sum of the\n",
    "    absolute values for the prediction and observed value at a\n",
    "    given time, then averages these devations over the length\n",
    "    of the series. This allows the SMAPE to have bounds between\n",
    "    0% and 200% which is desireble compared to normal MAPE that\n",
    "    may be undetermined when the target is zero.\n",
    "    \n",
    "    $$ \\mathrm{SMAPE}_{2}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \n",
    "       \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} \n",
    "       \\\\frac{|y_{\\\\tau}-\\hat{y}_{\\\\tau}|}{|y_{\\\\tau}|+|\\hat{y}_{\\\\tau}|} $$\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat: numpy array. \n",
    "            Predicted values.    \n",
    "        weights: numpy array, optional. \n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional. \n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the elements of \n",
    "            the input array. If axis is negative it counts from the last to first.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        smape: numpy array or double.\n",
    "            Return the SMAPE along the specified axis.\n",
    "    \"\"\"\n",
    "    _metric_protections(y, y_hat, weights)\n",
    "        \n",
    "    delta_y = np.abs(y - y_hat)\n",
    "    scale = np.abs(y) + np.abs(y_hat)\n",
    "    smape = _divide_no_nan(delta_y, scale)\n",
    "    smape = 200 * np.average(smape, weights=weights, axis=axis)\n",
    "    \n",
    "    if isinstance(smape, float):\n",
    "        assert smape <= 200, 'SMAPE should be lower than 200'\n",
    "    else:\n",
    "        assert all(smape <= 200), 'SMAPE should be lower than 200'\n",
    "    \n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkOrange\">3. Scale-independent Errors </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Scaled Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mase(y: np.ndarray, y_hat: np.ndarray, \n",
    "         y_train: np.ndarray,\n",
    "         seasonality: int,\n",
    "         weights: Optional[np.ndarray] = None,\n",
    "         axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculates the Mean Absolute Scaled Error (MASE) between\n",
    "    y and y_hat. MASE measures the relative prediction\n",
    "    accuracy of a forecasting method by comparinng the mean absolute errors\n",
    "    of the prediction and the observed value against the mean\n",
    "    absolute errors of the seasonal naive model.\n",
    "    The MASE partially composed the Overall Weighted Average (OWA), \n",
    "    used in the M4 Competition.\n",
    "    \n",
    "    $$ \\mathrm{MASE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{season}_{\\\\tau}) = \n",
    "        \\\\frac{1}{H} \\sum^{t+H}_{\\\\tau=t+1} \\\\frac{|y_{\\\\tau}-\\hat{y}_{\\\\tau}|}{\\mathrm{MAE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{season}_{\\\\tau})} $$\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat: numpy array. \n",
    "            Predicted values.   \n",
    "        y_train: numpy array. \n",
    "            Actual insample Seasonal Naive predictions.\n",
    "        seasonality: int.\n",
    "            Main frequency of the time series;\n",
    "            Hourly 24,  Daily 7, Weekly 52,\n",
    "            Monthly 12, Quarterly 4, Yearly 1.\n",
    "        weights: numpy array, optional. \n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional. \n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the elements of \n",
    "            the input array. If axis is negative it counts from the last to first.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mase: numpy array or double.\n",
    "            Return the mase along the specified axis.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] https://robjhyndman.com/papers/mase.pdf\n",
    "    \"\"\"    \n",
    "    delta_y = np.abs(y - y_hat)\n",
    "    delta_y = np.average(delta_y, weights=weights, axis=axis)\n",
    "    \n",
    "    scale = np.abs(y_train[:-seasonality] - y_train[seasonality:])\n",
    "    scale = np.average(scale, axis=axis)\n",
    "    \n",
    "    mase = delta_y / scale\n",
    "    \n",
    "    return mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "mase_loss_image = Image(filename='loss_imgs/mase_loss.png', width=WIDTH, height=HEIGHT)\n",
    "mase_loss_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rmae(y: np.ndarray, \n",
    "         y_hat1: np.ndarray, y_hat2: np.ndarray, \n",
    "         weights: Optional[np.ndarray] = None,\n",
    "         axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "            \n",
    "    Calculates Relative Mean Absolute Error (RMAE) between\n",
    "    two sets of forecasts (from two different forecasting methods).\n",
    "    A number smaller than one implies that the forecast in the \n",
    "    numerator is better than the forecast in the denominator.\n",
    "    \n",
    "    $$ \\mathrm{RMAE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{base}_{\\\\tau}) = \n",
    "        \\\\frac{1}{H} \\sum^{t+H}_{\\\\tau=t+1} \\\\frac{|y_{\\\\tau}-\\hat{y}_{\\\\tau}|}{\\mathrm{MAE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{base}_{\\\\tau})} $$\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat1: numpy array. \n",
    "            Predicted values of first model.\n",
    "        y_hat2: numpy array. \n",
    "            Predicted values of baseline model.\n",
    "        weights: numpy array, optional. \n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional. \n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the elements of \n",
    "            the input array. If axis is negative it counts from the last to first.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        rmae: numpy array or double.\n",
    "            Return the RMAE along the specified axis.\n",
    "    \"\"\"\n",
    "    numerator = mae(y=y, y_hat=y_hat1, weights=weights, axis=axis)\n",
    "    denominator = mae(y=y, y_hat=y_hat2, weights=weights, axis=axis)\n",
    "    rmae = numerator / denominator\n",
    "    \n",
    "    return rmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "rmae_image = Image(filename='loss_imgs/rmae_loss.png', width=WIDTH, height=HEIGHT)\n",
    "rmae_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkOrange\">4. Probabilistic Errors </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def quantile_loss(y: np.ndarray, y_hat: np.ndarray, q: float = 0.5, \n",
    "                  weights: Optional[np.ndarray] = None,\n",
    "                  axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Computes the quantile loss (QL) between y and y_hat. \n",
    "    QL measures the deviation of a quantile forecast.\n",
    "    By weighting the absolute deviation in a non symmetric way, the\n",
    "    loss pays more attention to under or over estimation.    \n",
    "    A common value for q is 0.5 for the deviation from the median.\n",
    "    \n",
    "    $$ \\mathrm{QL}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{(q)}_{\\\\tau}) = \n",
    "        \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} \n",
    "        \\Big( (1-q)\\,( \\hat{y}^{(q)}_{\\\\tau} - y_{\\\\tau} )_{+} \n",
    "        + q\\,( y_{\\\\tau} - \\hat{y}^{(q)}_{\\\\tau} )_{+} \\Big) $$            \n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat: numpy array. \n",
    "            Predicted values.    \n",
    "        q: float. \n",
    "            Quantile for the predictions' comparison.\n",
    "        weights: numpy array, optional. \n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional. \n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the elements of \n",
    "            the input array. If axis is negative it counts from the last to first.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        quantile_loss: numpy array or double.\n",
    "            Return the QL along the specified axis.\n",
    "    \"\"\"\n",
    "    _metric_protections(y, y_hat, weights)\n",
    "\n",
    "    delta_y = y - y_hat\n",
    "    loss = np.maximum(q * delta_y, (q - 1) * delta_y)\n",
    "\n",
    "    if weights is not None:\n",
    "        quantile_loss = np.average(loss[~np.isnan(loss)], \n",
    "                             weights=weights[~np.isnan(loss)],\n",
    "                             axis=axis)\n",
    "    else:\n",
    "        quantile_loss = np.nanmean(loss, axis=axis)\n",
    "        \n",
    "    return quantile_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "qloss_image = Image(filename='loss_imgs/q_loss.png', width=WIDTH, height=HEIGHT)\n",
    "qloss_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Quantile Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mqloss(y: np.ndarray, y_hat: np.ndarray, \n",
    "           quantiles: np.ndarray, \n",
    "           weights: Optional[np.ndarray] = None,\n",
    "           axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculates the Multi-Quantile loss (MQL) between y and y_hat. \n",
    "    MQL calculates the average multi-quantile Loss for\n",
    "    a given set of quantiles, based on the absolute \n",
    "    difference between predicted quantiles and observed values.\n",
    "        \n",
    "    $$ \\mathrm{MQL}(\\\\mathbf{y}_{\\\\tau},\n",
    "                    [\\\\mathbf{\\hat{y}}^{(q_{1})}_{\\\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\\\tau}]) = \n",
    "       \\\\frac{1}{n} \\\\sum_{q_{i}} \\mathrm{QL}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{(q_{i})}_{\\\\tau}) $$\n",
    "    \n",
    "    The limit behavior of MQL allows to measure the accuracy \n",
    "    of a full predictive distribution $\\mathbf{\\hat{F}}_{\\\\tau}$ with \n",
    "    the continuous ranked probability score (CRPS). This can be achieved \n",
    "    through a numerical integration technique, that discretizes the quantiles \n",
    "    and treats the CRPS integral with a left Riemann approximation, averaging over \n",
    "    uniformly distanced quantiles.    \n",
    "    \n",
    "    $$ \\mathrm{CRPS}(y_{\\\\tau}, \\mathbf{\\hat{F}}_{\\\\tau}) = \n",
    "        \\int^{1}_{0} \\mathrm{QL}(y_{\\\\tau}, \\hat{y}^{(q)}_{\\\\tau}) dq $$          \n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat: numpy array. \n",
    "            Predicted values.    \n",
    "        quantiles: numpy array. \n",
    "            Quantiles to compare against.\n",
    "        weights: numpy array, optional. \n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional. \n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the elements of \n",
    "            the input array. If axis is negative it counts from the last to first.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mqloss: numpy array or double.\n",
    "            Return the MQL along the specified axis.\n",
    "            \n",
    "        References\n",
    "        ----------\n",
    "        [1] https://www.jstor.org/stable/2629907            \n",
    "    \"\"\" \n",
    "    if weights is None: weights = np.ones(y.shape)\n",
    "        \n",
    "    _metric_protections(y, y_hat, weights)\n",
    "    n_q = len(quantiles)\n",
    "    \n",
    "    y_rep  = np.expand_dims(y, axis=-1)\n",
    "    error  = y_rep - y_hat\n",
    "    mqloss = np.maximum(quantiles * error, (quantiles - 1) * error)\n",
    "    \n",
    "    # Match y/weights dimensions and compute weighted average\n",
    "    weights = np.repeat(np.expand_dims(weights, axis=-1), repeats=n_q, axis=-1)\n",
    "    mqloss  = np.average(mqloss, weights=weights, axis=axis)\n",
    "\n",
    "    return mqloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "mqloss_image = Image(filename='loss_imgs/mq_loss.png', width=WIDTH, height=HEIGHT)\n",
    "mqloss_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def coverage(\n",
    "        y: np.ndarray, y_hat_lo: np.ndarray, y_hat_hi: np.ndarray, \n",
    "    ) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculates the coverage of y with y_hat_lo and y_hat_hi. \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat_lo: numpy array. \n",
    "            Lower prediction interval.\n",
    "        y_hat_hi: numpy array. \n",
    "            Higher prediction interval.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        coevrage: numpy array or double.\n",
    "            Return the coverage of y_hat.\n",
    "            \n",
    "        References\n",
    "        ----------\n",
    "        [1] https://www.jstor.org/stable/2629907            \n",
    "    \"\"\" \n",
    "    return 100 * np.logical_and(y>=y_hat_lo, y<=y_hat_hi).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calibration(\n",
    "        y: np.ndarray, y_hat_hi: np.ndarray, \n",
    "    ) -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculates the fraction of y that is lower than y_hat_hi. \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat_hi: numpy array. \n",
    "            Higher prediction interval.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        coevrage: numpy array or double.\n",
    "            Return the coverage of y_hat.\n",
    "            \n",
    "        References\n",
    "        ----------\n",
    "        [1] https://www.jstor.org/stable/2629907            \n",
    "    \"\"\" \n",
    "    return (y<=y_hat_hi).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def scaled_crps(y: np.ndarray, y_hat: np.ndarray, \n",
    "                quantiles: np.ndarray, \n",
    "                weights: Optional[np.ndarray] = None,\n",
    "                axis: Optional[int] = None) -> Union[float, np.ndarray]:\n",
    "    \"\"\"Scaled Continues Ranked Probability Score\n",
    "    \n",
    "    Calculates a scaled variation of the CRPS, as proposed by Rangapuram (2021),\n",
    "    to measure the accuracy of predicted quantiles `y_hat` compared to the observation `y`.\n",
    "    This metric averages percentual weighted absolute deviations as \n",
    "    defined by the quantile losses.\n",
    "    \n",
    "    $$ \\mathrm{sCRPS}(\\hat{F}_{\\\\tau}, \\mathbf{y}_{\\\\tau}) = \\\\frac{2}{N} \\sum_{i}\n",
    "    \\int^{1}_{0}\n",
    "    \\\\frac{\\mathrm{QL}(\\hat{F}_{i,\\\\tau}, y_{i,\\\\tau})_{q}}{\\sum_{i} | y_{i,\\\\tau} |} dq $$\n",
    "    \n",
    "    Where $\\hat{F}_{\\\\tau}$ is the an estimated multivariate distribution, and $y_{i,\\\\tau}$\n",
    "    are its realizations.        \n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy array. \n",
    "            Observed values.\n",
    "        y_hat: numpy array. \n",
    "            Predicted values.    \n",
    "        quantiles: numpy array. \n",
    "            Quantiles to compare against.\n",
    "        weights: numpy array, optional. \n",
    "            Weights for weighted average.\n",
    "        axis: None or int, optional. \n",
    "            Axis or axes along which to average a. \n",
    "            The default, axis=None, will average over all of the elements of \n",
    "            the input array. If axis is negative it counts from the last to first.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scaled_crps: numpy array or double.\n",
    "            Return the scaled crps along the specified axis.\n",
    "            \n",
    "        References\n",
    "        ----------\n",
    "        [1] https://proceedings.mlr.press/v139/rangapuram21a.html      \n",
    "    \"\"\" \n",
    "    eps = np.finfo(float).eps\n",
    "    norm  = np.sum(np.abs(y))\n",
    "    loss  = mqloss(y=y, y_hat=y_hat, quantiles=quantiles, weights=weights, axis=axis)\n",
    "    loss  = 2 * loss * np.sum(np.ones(y.shape)) / (norm + eps)\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
