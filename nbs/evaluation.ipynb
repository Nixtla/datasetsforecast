{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pickle\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fugue import transform\n",
    "from fugue.collections.yielded import Yielded\n",
    "from fugue.constants import FUGUE_CONF_WORKFLOW_EXCEPTION_INJECT\n",
    "from fugue.dataframe import DataFrame\n",
    "from fugue.workflow import FugueWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _cotransform(\n",
    "    df1: Any,\n",
    "    df2: Any,\n",
    "    using: Any,\n",
    "    schema: Any = None,\n",
    "    params: Any = None,\n",
    "    partition: Any = None,\n",
    "    engine: Any = None,\n",
    "    engine_conf: Any = None,\n",
    "    force_output_fugue_dataframe: bool = False,\n",
    "    as_local: bool = False,\n",
    ") -> Any:\n",
    "    dag = FugueWorkflow(compile_conf={FUGUE_CONF_WORKFLOW_EXCEPTION_INJECT: 0})\n",
    "    src = dag.create_data(df1).zip(dag.create_data(df2), partition=partition)\n",
    "    tdf = src.transform(\n",
    "        using=using,\n",
    "        schema=schema,\n",
    "        params=params,\n",
    "        pre_partition=partition,\n",
    "    )\n",
    "    tdf.yield_dataframe_as(\"result\", as_local=as_local)\n",
    "    dag.run(engine, conf=engine_conf)\n",
    "    result = dag.yields[\"result\"].result  # type:ignore\n",
    "    if force_output_fugue_dataframe or isinstance(df1, (DataFrame, Yielded)):\n",
    "        return result\n",
    "    return result.as_pandas() if result.is_local else result.native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _evaluate(\n",
    "        df: pd.DataFrame, \n",
    "        df_train: pd.DataFrame,\n",
    "        metrics: Optional[List[Callable]] = None,\n",
    "        id_col: str = 'unique_id',\n",
    "        time_col: str = 'ds',\n",
    "        target_col: str = 'y',\n",
    "        level: Optional[List] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "    cols_to_rm = '|'.join([id_col, time_col, target_col, 'cutoff', 'lo', 'hi'])\n",
    "    has_cutoff = 'cutoff' in df.columns\n",
    "    models = df.loc[:, ~df.columns.str.contains(cols_to_rm)].columns\n",
    "    y = df[target_col].values\n",
    "    eval_ = {}\n",
    "    for model in models:\n",
    "        eval_[model] = {}\n",
    "        for metric in metrics:\n",
    "            y_hat = df[model].values\n",
    "            metric_name = metric.__name__\n",
    "            if 'mase' in metric_name:\n",
    "                if df_train is None:\n",
    "                    raise Exception('Please provide `Y_df` to compute mase')\n",
    "                metric_res = metric(y, y_hat, df_train[target_col].values)\n",
    "            else:\n",
    "                metric_res = metric(y, y_hat)\n",
    "            eval_[model][metric_name] = metric_res\n",
    "    eval_df = pd.DataFrame(eval_).rename_axis('metric').reset_index()\n",
    "    if has_cutoff:\n",
    "        eval_df.insert(0, 'cutoff', df['cutoff'].iloc[0])\n",
    "    eval_df.insert(0, id_col, df[id_col].iloc[0])\n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _evaluate_without_insample(\n",
    "        df: pd.DataFrame, \n",
    "        metrics: Optional[List[Callable]] = None,\n",
    "        id_col: str = 'unique_id',\n",
    "        time_col: str = 'ds',\n",
    "        target_col: str = 'y',\n",
    "        level: Optional[List] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "    return _evaluate(\n",
    "        df=df, df_train=None, metrics=metrics, id_col=id_col, time_col=time_col,\n",
    "        target_col=target_col, level=level,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _schema_evaluate(\n",
    "        df: pd.DataFrame,\n",
    "        id_col: str = 'unique_id',\n",
    "        time_col: str = 'ds',\n",
    "        target_col: str = 'y',\n",
    "    ):\n",
    "    cols_to_rm = '|'.join([id_col, time_col, target_col, 'cutoff', 'lo', 'hi'])\n",
    "    has_cutoff = 'cutoff' in df.columns\n",
    "    models = df.loc[:, ~df.columns.str.contains(cols_to_rm)].columns\n",
    "    str_models = ','.join([f\"{model}:double\" for model in models])\n",
    "    dtypes = df.dtypes\n",
    "    id_col_type = dtypes.loc[id_col]\n",
    "    if id_col_type == 'category':\n",
    "        raise NotImplementedError(\n",
    "            'Use of `category` type to identify each time series is not yet implemented. '\n",
    "            f'Please transform your {id_col} to string to continue.'\n",
    "        )\n",
    "    id_col_type = 'string' if id_col_type == 'object' else id_col_type\n",
    "    cutoff_col_type = ''\n",
    "    if has_cutoff:\n",
    "        cutoff_col_type = f\"{dtypes.loc['cutoff']}\".replace('64[ns]', '')\n",
    "        cutoff_col_type = 'string' if cutoff_col_type == 'object' else cutoff_col_type\n",
    "    schema = (\n",
    "        f'{id_col}:{id_col_type},metric:string,'\n",
    "        + (f'cutoff:{cutoff_col_type},' if has_cutoff else '')\n",
    "        + str_models\n",
    "    )\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _agg_evaluation(\n",
    "        df_eval: pd.DataFrame, \n",
    "        agg_fn: Any, \n",
    "        agg_by: Any,\n",
    "    ) -> pd.DataFrame:\n",
    "    cols_to_rm = '|'.join(agg_by + ['unique_id', 'metric', 'cutoff', 'lo', 'hi'])\n",
    "    models = df_eval.loc[:, ~df_eval.columns.str.contains(cols_to_rm)].columns\n",
    "    return df_eval.groupby(agg_by)[models].apply(agg_fn, axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _schema_agg_evaluation(\n",
    "        df: pd.DataFrame, \n",
    "        agg_by: Optional[List[str]] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "    cols_to_rm = '|'.join(agg_by + ['unique_id', 'metric', 'cutoff', 'lo', 'hi'])\n",
    "    models = df.loc[:, ~df.columns.str.contains(cols_to_rm)].columns\n",
    "    str_models = ','.join([f'{model}:double' for model in models])\n",
    "    dtypes = df.dtypes\n",
    "    agg_by_types = [dtypes.loc[col] for col in agg_by]\n",
    "    if 'category' in agg_by_types:\n",
    "        raise NotImplementedError(\n",
    "            'Use of `category` type is not yet implemented. '\n",
    "            f'Please transform your columns to string to continue.'\n",
    "        )\n",
    "    agg_by_types = ['string' if col == 'object' else col for col in agg_by_types]\n",
    "    agg_by_types = [col.replace('64[ns]', '') for col in agg_by_types]\n",
    "    schema = [f'{col}:{type_}' for col, type_ in zip(agg_by, agg_by_types)]\n",
    "    schema = ','.join(schema) + ',' + str_models\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq, test_fail, test_close\n",
    "from datasetsforecast.m4 import M4, M4Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/1l3vkh3x4_q3s4r36b60s8f00000gn/T/ipykernel_44075/3530693183.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_hourly['FFORMA'] = eval_test['FFORMA'].values\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "fforma_url = 'https://github.com/Nixtla/m4-forecasts/raw/master/forecasts/submission-245.zip'\n",
    "M4Evaluation.load_benchmark('data', 'Hourly', fforma_url)\n",
    "eval_test = pd.read_csv('data/m4/datasets/submission-245.csv').query(\"id.str.startswith('H')\")\n",
    "eval_test = eval_test.set_index('id')\n",
    "eval_test.columns = list(range(1, 49))\n",
    "eval_test = eval_test.unstack().reset_index()\n",
    "eval_test.columns = ['ds', 'unique_id', 'FFORMA']\n",
    "eval_test = eval_test[['unique_id', 'ds', 'FFORMA']].sort_values(['unique_id', 'ds'])\n",
    "hourly, *_ = M4.load('data', 'Hourly')\n",
    "test_hourly = hourly.groupby('unique_id').tail(48)\n",
    "train_hourly = hourly.drop(test_hourly.index)\n",
    "test_hourly['FFORMA'] = eval_test['FFORMA'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    _schema_evaluate(eval_test),\n",
    "    'unique_id:string,metric:string,FFORMA:double'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate_forecast(\n",
    "        Y_hat_df: pd.DataFrame,\n",
    "        metrics: List[Callable],\n",
    "        Y_test_df: Optional[pd.DataFrame] = None,\n",
    "        Y_df: Optional[pd.DataFrame] = None,\n",
    "        id_col: str = 'unique_id',\n",
    "        time_col: str = 'ds',\n",
    "        target_col: str = 'y',\n",
    "        level: Optional[List] = None,\n",
    "        agg_fn: Callable = np.mean,\n",
    "        agg_by: Optional[List[str]] = None,\n",
    "        engine: Any = None,\n",
    "        **transform_kwargs: Any,\n",
    "    ) -> pd.DataFrame:\n",
    "    if 'y' not in Y_hat_df.columns:\n",
    "        raise Exception(\n",
    "            'Please include the actual values in `Y_hat_df` '\n",
    "            'or pass `Y_test_df`.'\n",
    "        )\n",
    "    df = Y_hat_df if Y_test_df is None else Y_hat_df.merge(Y_test_df, how='left', on=[id_col, time_col])\n",
    "    transform_fn = partial(_cotransform, df2=Y_df) if Y_df is not None else transform   \n",
    "    if Y_df is None:\n",
    "        fn = _evaluate_without_insample\n",
    "    else:\n",
    "        fn = _evaluate\n",
    "    has_cutoff = 'cutoff' in Y_hat_df.columns\n",
    "    evaluation_df = transform_fn(\n",
    "        df, \n",
    "        using=fn, \n",
    "        engine=engine, \n",
    "        params=dict(\n",
    "            metrics=metrics,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "            level=level,\n",
    "        ), \n",
    "        schema=_schema_evaluate(\n",
    "            df, \n",
    "            id_col=id_col, \n",
    "            time_col=time_col, \n",
    "            target_col=target_col,\n",
    "        ), \n",
    "        partition=dict(by=id_col) if not has_cutoff else dict(by=[id_col, 'cutoff']),\n",
    "    )\n",
    "    if agg_by is not None:\n",
    "        agg_by = ['metric'] + agg_by\n",
    "    else:\n",
    "        agg_by = ['metric']\n",
    "    evaluation_df = transform(\n",
    "        evaluation_df,\n",
    "        using=_agg_evaluation,\n",
    "        engine=engine,\n",
    "        params=dict(agg_fn=agg_fn, agg_by=agg_by),\n",
    "        schema=_schema_agg_evaluation(evaluation_df, agg_by),\n",
    "        partition=agg_by,\n",
    "        **transform_kwargs,\n",
    "    )\n",
    "    return evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from datasetsforecast.losses import smape, mase, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def mase_24(y, y_hat, y_train):\n",
    "    return mase(y, y_hat, y_train, seasonality=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_cutoff = pd.concat([test_hourly.assign(cutoff=str(i), model1=0) for i in range(3)])\n",
    "eval_cutoff = evaluate_forecast(test_cutoff, metrics=[smape, mape], agg_by=['cutoff'])\n",
    "test_eq(\n",
    "    eval_cutoff.shape,\n",
    "    (6, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_close(\n",
    "    evaluate_forecast(test_hourly, Y_df=train_hourly, metrics=[smape, mase_24])['FFORMA'].values,\n",
    "    np.array([0.818598, 11.505702])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(\n",
    "    evaluate_forecast(test_hourly, Y_df=train_hourly, metrics=[smape]),\n",
    "    evaluate_forecast(test_hourly, metrics=[smape])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:_1 _State.RUNNING -> _State.FAILED  Please provide `Y_df` to compute mase\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "test_fail(\n",
    "    lambda : evaluate_forecast(test_hourly, metrics=[smape, mase]), \n",
    "    contains='mase'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
